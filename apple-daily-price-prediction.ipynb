{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-04T11:57:03.438146Z","iopub.execute_input":"2022-04-04T11:57:03.438596Z","iopub.status.idle":"2022-04-04T11:57:03.457844Z","shell.execute_reply.started":"2022-04-04T11:57:03.438505Z","shell.execute_reply":"2022-04-04T11:57:03.456788Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/apple-aapl-historical-stock-data/HistoricalQuotes.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# gather data\ndf = pd.read_csv('/kaggle/input/apple-aapl-historical-stock-data/HistoricalQuotes.csv')\ndf.columns = ['Date', 'Close', 'Volume', 'Open', 'High', 'Low']\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import yfinance as yf\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-17T10:03:51.466651Z","iopub.execute_input":"2021-10-17T10:03:51.467257Z","iopub.status.idle":"2021-10-17T10:03:51.54486Z","shell.execute_reply.started":"2021-10-17T10:03:51.467133Z","shell.execute_reply":"2021-10-17T10:03:51.543453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocess Data","metadata":{}},{"cell_type":"code","source":"# Reverse order of dataframe\ndf = (df.iloc[::-1])\ndf = df.reset_index(drop = True)\n\n# Convert date into datetime object, then into cyclical function using sin function\n# Retain year as seperate feature\n\ndf['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%Y')\ndf['Year'] = pd.DatetimeIndex(df['Date']).year - 2010\ndf['DayOfYear'] = df['Date'].dt.dayofyear\n\ntemp = pd.DataFrame()\ntemp = df['DayOfYear']/df['DayOfYear'].max() * 2 * np.pi\ntemp = np.sin(temp) # Uses sin\nprint(temp)\n\ndf['DayOfYear'] = temp\n\n# Remove dollar signs\ndf['Close'] = df['Close'].str.replace('$', '')\ndf['Open'] = df['Open'].str.replace('$', '')\ndf['High'] = df['High'].str.replace('$', '')\ndf['Low'] = df['Low'].str.replace('$', '')\n\ndf.head()\n\n# Normalize volume between 0 and 1\n\ndf['Volume']=(df['Volume']-df['Volume'].min())/(df['Volume'].max()-df['Volume'].min())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create MACD Column\n\n# Traditional MACD = 12 Day EMA - 26 Day EMA, EMA = Exponential Moving Average\n# Using closing prices\n\n#EMA\nema12 = df['Close'].ewm(span=12, min_periods=12)\nema12 = ema12.mean() # First 11 values are null\nema20 = df['Close'].ewm(span=26, min_periods=26)\nema20 = ema20.mean() # First 25 values are null\n\n#Add MACD to dataframe\ndf['MACD'] = ema12 - ema20\n\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Stochastic RSI Column\n# https://stackoverflow.com/questions/30261541/slow-stochastic-implementation-in-python-pandas\n\nk = 14 # days\nd = 3\n\nlow_min  = df['Low'].rolling(window=k).min()\nhigh_max = df['High'].rolling( window=k).max()\n\ndf['Close'] = df['Close'].astype('float64')\ndf['Stoch_k'] = 100 * (df['Close'] - low_min)/(high_max - low_min)\ndf['Stoch_d'] = df['Stoch_k'].rolling(window=d).mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create label(s)\n\ndf['Y1'] = df['Close'].copy().shift(periods=1) # Price after 1 day\ndf['Y7'] = df['Close'].copy().shift(periods=7) # Price after 7 days\ndf['Y30'] = df['Close'].copy().shift(periods=30) # Price after 30 days\n\n# Remove missing data\n\ndf = df.dropna()\ndf = df.reset_index(drop = True)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create features and labels, testing with different features and labels\n# X1 and X2 are paired with y1, y7, and y30\n# X3 is paired with y30_2\n\nX1 = df[['Close', 'Volume', 'Year', 'DayOfYear', 'MACD', 'Stoch_k', 'Stoch_d']] # Removed Open, High, Low\nX2 = df[['Close', 'Volume', 'Open', 'High', 'Low', 'Year', 'DayOfYear', 'MACD', 'Stoch_k', 'Stoch_d']]\nX3 = df[['Volume', 'Year', 'DayOfYear', 'MACD', 'Stoch_k', 'Stoch_d']] # Removed all price data\n\ny1 = df['Y1']\ny7 = df['Y7']\ny30 = df['Y30']\n\ny30_2 = df['Y30'] - df['Close'] # Difference between two closing prices\n\n# Control, to see if technical indicators helped predict price or not\n# 30 Day prediction\n\nX_control = df[['Close', 'Volume', 'Open', 'High', 'Low', 'Year', 'DayOfYear']] # Removed Technical Indicators\ny_control = df['Y30']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Model","metadata":{}},{"cell_type":"code","source":"# X1 and y1: 1 DAY PREDICTION\n# 90% train, 5% valid, 5% test\nfrom sklearn import tree, metrics, datasets, model_selection\n\nX1_train, X1_temp, y1_train, y1_temp = model_selection.train_test_split(X1,y1, test_size = 0.1)\nX1_valid, X1_test, y1_valid, y1_test = model_selection.train_test_split(X1_temp, y1_temp, test_size = 0.5) \nprint(X1_train.shape, X1_valid.shape, X1_test.shape)\n\n\nmodel1 = tree.DecisionTreeRegressor(max_depth = 10, min_samples_split = 2) \nmodel1.fit(X1_train, y1_train)\n\ny1_pred = model1.predict(X1_valid) # y1_pred \nprint('Model1 1 Day MAE Validation Score:',metrics.mean_absolute_error(y1_valid, y1_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X1 and y7: 7 DAY PREDICTION\nX1_train, X1_temp, y7_train, y7_temp = model_selection.train_test_split(X1,y7, test_size = 0.1)\nX1_valid, X1_test, y7_valid, y2_test = model_selection.train_test_split(X1_temp, y7_temp, test_size = 0.5) \n\nmodel2 = tree.DecisionTreeRegressor(max_depth = 10, min_samples_split = 2) \nmodel2.fit(X1_train, y7_train)\n\ny7_pred = model2.predict(X1_valid)\nprint('Model2 7 Day MAE Validation Score:',metrics.mean_absolute_error(y7_valid, y7_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X2 and y7: 7 DAY PREDICTION w/ high, low, open prices as features\n\nX2_train, X2_temp, y7_train, y7_temp = model_selection.train_test_split(X2,y7, test_size = 0.1)\nX2_valid, X2_test, y7_valid, y3_test = model_selection.train_test_split(X2_temp, y7_temp, test_size = 0.5) \n\nmodel3 = tree.DecisionTreeRegressor(max_depth = 10, min_samples_split = 2) \nmodel3.fit(X2_train, y7_train)\n\ny7_pred = model3.predict(X2_valid)\nprint('Model3 7 Day MAE Validation Score:',metrics.mean_absolute_error(y7_valid, y7_pred))\n\nplt.plot(y7_pred)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X2 and y30 v.s. X3 and y30_2\n# Both are 30 day predictions, but have different features\n# The MAEs of both models should be comparable with each other... I think\n\nX2_train, X2_temp, y30_train, y30_temp = model_selection.train_test_split(X2,y30, test_size = 0.1)\nX2_valid, X2_test, y30_valid, y4_test = model_selection.train_test_split(X2_temp, y30_temp, test_size = 0.5) \n\nmodel4 = tree.DecisionTreeRegressor(criterion = 'mae', max_depth = 10, min_samples_split = 2) \nmodel4.fit(X2_train, y30_train)\n\ny30_pred = model4.predict(X2_valid)\n\nX3_train, X3_temp, y30_2_train, y30_2_temp = model_selection.train_test_split(X2,y30_2,test_size = 0.1)\nX3_valid, X3_test, y30_2_valid, y5_test = model_selection.train_test_split(X2_temp, y30_2_temp, test_size = 0.5) \n\nmodel5 = tree.DecisionTreeRegressor(criterion = 'mae', max_depth = 10, min_samples_split = 2) \nmodel5.fit(X3_train, y30_2_train)\n\ny30_2_pred = model5.predict(X3_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_Control = df[['Close', 'Volume', 'Open', 'High', 'Low', 'Year', 'DayOfYear']] # Removed Technical Indicators\ny_control = df['Y30']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Control model: 30 day prediction\n\nX_control_train, X_control_temp, y_control_train, y_control_temp = model_selection.train_test_split(X_control, y_control, test_size = 0.1)\nX_control_valid, X_control_test, y_control_valid, y_control_test = model_selection.train_test_split(X_control_temp, y_control_temp, test_size = 0.5) \n\nmodel6 = tree.DecisionTreeRegressor(criterion = 'mae', max_depth = 10, min_samples_split = 2) \nmodel6.fit(X_control_train, y_control_train)\n\ny_control_pred = model6.predict(X_control_valid)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tested hyperparameters:\n\nmax_depth: doesnt seem to have a significant effect from 1-1024\n\nsplitter: best > random\n\nmin_samples_split: 2, 4, 8 are best. tested powers of 2 until 2^6, then powers of 10 until 10^6","metadata":{}},{"cell_type":"code","source":"print('Model4 30 Day MAE Validation score: ',metrics.mean_absolute_error(y30_valid, y30_pred))\nprint('Model5 30 Day MAE Validation score: ',metrics.mean_absolute_error(y30_2_valid, y30_2_pred))\nprint('Control Model 30 Day MAE Validation score: ',metrics.mean_absolute_error(y_control_valid, y_control_pred))\nplt.plot(y30_pred)\nplt.plot(y_control_pred)\nplt.show()\n\n# X2 is blue, Control is orange","metadata":{"execution":{"iopub.status.busy":"2021-12-17T17:45:14.620293Z","iopub.execute_input":"2021-12-17T17:45:14.620707Z","iopub.status.idle":"2021-12-17T17:45:14.686411Z","shell.execute_reply.started":"2021-12-17T17:45:14.620616Z","shell.execute_reply":"2021-12-17T17:45:14.685165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction of 30 day stock price relative to starting price\nprint('Model5 MAE Validation score: ',metrics.mean_absolute_error(y30_2_valid, y30_2_pred))\nplt.plot(y30_2_pred)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1_predictions = model1.predict(X1_test)\nmodel2_predictions = model2.predict(X1_test)\nmodel3_predictions = model3.predict(X2_test)\nmodel4_predictions = model4.predict(X2_test)\nmodel5_predictions = model5.predict(X3_test) # predicts price change instead of absolute price\ncontrol_model_predictions = model6.predict(X_control_test)\nprint('Model1 1 Day MAE Test Score:',metrics.mean_absolute_error(y1_test, model1_predictions))\nprint('Model2 7 Day MAE Test Score:',metrics.mean_absolute_error(y2_test, model2_predictions))\nprint('Model3 7 Day MAE Test Score:',metrics.mean_absolute_error(y3_test, model3_predictions))\nprint('Model4 30 Day MAE Test score: ',metrics.mean_absolute_error(y4_test, model4_predictions))\nprint('Model5 30 Day MAE Test score: ',metrics.mean_absolute_error(y5_test, model5_predictions))\nprint('Control 30 Day MAE Test score:',metrics.mean_absolute_error(y_control_test, control_model_predictions))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}